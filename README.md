
# Facial Emotion Recognition
Facial Expression Recognition involves predicting a person's emotions through images.

<img src="https://github.com/ankursinghbisht/Facial_Emotion_Recognition/assets/112644477/2aacf910-bbe1-4dd9-9a05-7f9141b79548" alt="image" width="600"/>

## Introduction

Within the scope of this project, our objective was to classify a person's emotions by analyzing their images. To accomplish this, we trained a model capable of categorizing emotions into seven distinct types: happiness, sadness, anger, disgust, neutrality, fear, and surprise.
## Why I Built it?
- Enhancing Human-Computer Interaction: I recognized the significance of developing more intuitive and natural ways for humans to interact with technology. By enabling machines to understand and respond to human emotions, we can create interfaces and systems that adapt to users' emotional states, leading to a more seamless and empathetic interaction.

- Improving Mental Health Support: Emotions play a crucial role in mental well-being. I wanted to contribute to the field of mental health by building a tool that could potentially help identify and track emotional patterns in individuals. This could provide valuable insights to therapists, counselors, or individuals themselves, facilitating a better understanding of emotional states and potentially aiding in early intervention.

- Personalized Content and Marketing: Emotion recognition from images can have substantial applications in marketing and content creation. Businesses can tailor their products, advertisements, and services based on the emotional responses of their customers. By understanding how people react to different visuals, companies can create more relatable and engaging campaigns.

- Security and Surveillance: In certain contexts, such as security or surveillance, emotion recognition could have applications in identifying potential threats or detecting unusual behavior. For instance, it might be used to monitor crowd emotions in public spaces.





## How can I execute my project?

To get started with the Chess Game, follow these simple steps:

- Clone the repository to your local machine.

- Install the required dependencies using `pip install`.
- Download the dataset from 'https://www.kaggle.com/datasets/msambare/fer2013' and store it within your local repository.

- Execute 'Model.ipynb'.
    
## Screenshots
### DataSet ( FER 2013)

<img src="https://github.com/ankursinghbisht/Facial_Emotion_Recognition/assets/112644477/cb87cb85-4cab-484e-a4a7-5da5efdaf4ae" alt="image" width="300"/>

### Results
<img src="https://github.com/ankursinghbisht/Facial_Emotion_Recognition/assets/112644477/1e7d1877-9e26-42b9-953b-37e554239eed" alt="image" width="300"/>
<img src="https://github.com/ankursinghbisht/Facial_Emotion_Recognition/assets/112644477/bebaf764-825a-4fbd-98a7-4b4924eace3b" alt="image" width="300"/>





## ðŸ”— Links
[![portfolio](https://img.shields.io/badge/my_portfolio-000?style=for-the-badge&logo=ko-fi&logoColor=white)](https://github.com/ankursinghbisht?tab=repositories)
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/ankursinghbisht/)

